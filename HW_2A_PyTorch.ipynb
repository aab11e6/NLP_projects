{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2BVH_JD9WiA"
      },
      "source": [
        "Below we will try and fit a Logisitc Regression Model step by step for the XOR problem.\n",
        "Fill in the code where there is a `_FILL_` specified. For this model, we have $x_1$ and $x_2$ are either 0/1 each and $y = x_1 + x_2 - 2x_1x_2$. Notice that this is True (1) if $x_1 = 1$ and $x_2 = 0$ OR $x_1 = 0$ and $x_2 = 1$; $y$ is zero otherwise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wiFGf-9H9X3d"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch\n",
        "# Don't fill this in\n",
        "_FILL_ = '_FILL_'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1TRwUp469X-r"
      },
      "outputs": [],
      "source": [
        "x_data = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
        "y_data = [[0], [1], [1], [0]]\n",
        "x_data = torch.Tensor(x_data)\n",
        "y_data = torch.Tensor(y_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2FJM6ckGBRz_"
      },
      "outputs": [],
      "source": [
        "# Define each tensor to be 1x1 and have them require a gradient for tracking; these are parameters\n",
        "alpha = nn.Parameter(torch.Tensor(1,1),requires_grad=True)\n",
        "beta_1 = nn.Parameter(torch.Tensor(1,1),requires_grad=True)\n",
        "beta_2 = nn.Parameter(torch.Tensor(1,1),requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BToqdBCr9YBI",
        "outputId": "f7acc5be-2e68-4085-c6ef-b4514bb474df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "Loss: 0.6931471824645996 Accuracy: 0.5\n",
            "Epoch: 1\n",
            "Loss: 0.6931471228599548 Accuracy: 0.5\n",
            "Epoch: 2\n",
            "Loss: 0.6931471824645996 Accuracy: 0.5\n",
            "Epoch: 3\n",
            "Loss: 0.6931471824645996 Accuracy: 0.5\n",
            "Epoch: 4\n",
            "Loss: 0.6931472420692444 Accuracy: 0.5\n",
            "Epoch: 5\n",
            "Loss: 0.6931471824645996 Accuracy: 0.5\n",
            "Epoch: 6\n",
            "Loss: 0.6931471824645996 Accuracy: 0.5\n",
            "Epoch: 7\n",
            "Loss: 0.6931471824645996 Accuracy: 0.5\n",
            "Epoch: 8\n",
            "Loss: 0.6931472420692444 Accuracy: 0.5\n",
            "Epoch: 9\n",
            "Loss: 0.6931472420692444 Accuracy: 0.5\n"
          ]
        }
      ],
      "source": [
        "lr = 0.01\n",
        "\n",
        "for epoch in range(10):\n",
        "  for x, y in zip(x_data, y_data):\n",
        "\n",
        "    # Have z be beta_2*x[0] + beta_1*x[1] + alpha\n",
        "    z = beta_2*x[0] + beta_1*x[1] + alpha\n",
        "\n",
        "    # Push z through a nn.Sigmoid layer to get the p(y=1)\n",
        "    a = nn.Sigmoid()(z)\n",
        "\n",
        "    # Write the loss manually between y and a\n",
        "    loss = -y*torch.log(a)-(1-y)*torch.log(1-a)\n",
        "\n",
        "    # Get the loss gradients; the gradients with respect to alpha, beta_1, beta_2\n",
        "    loss.backward()\n",
        "\n",
        "    # Manually update the gradients\n",
        "    grad_alpha = alpha.grad\n",
        "    grad_beta_1 = beta_1.grad\n",
        "    grad_beta_2 = beta_2.grad\n",
        "    # What we do below is wrapped within this clause because weights have required_grad=True but we don't need to track this in autograd\n",
        "    with torch.no_grad():\n",
        "        # Do an update for each parameter\n",
        "        alpha -= lr*grad_alpha\n",
        "        beta_1 -= lr*grad_beta_1\n",
        "        beta_2 -= lr*grad_beta_2\n",
        "\n",
        "        # Manually zero the gradients after updating weights\n",
        "        alpha.grad.zero_()\n",
        "        beta_1.grad.zero_()\n",
        "        beta_2.grad.zero_()\n",
        "\n",
        "  # Manually get the accuracy of the model after each epoch\n",
        "  with torch.no_grad():\n",
        "    print(f'Epoch: {epoch}')\n",
        "    y_pred = []\n",
        "    loss = 0.0\n",
        "\n",
        "    for x, y in zip(x_data, y_data):\n",
        "      # Get z\n",
        "      z = beta_2*x[0] + beta_1*x[1] + alpha\n",
        "\n",
        "      # Get a\n",
        "      a = nn.Sigmoid()(z)\n",
        "\n",
        "      # Get the loss\n",
        "      loss += -y*torch.log(a)-(1-y)*torch.log(1-a)\n",
        "\n",
        "      # Get the prediction given a\n",
        "      prediction = (a > 0.5)\n",
        "      y_pred.append(prediction)\n",
        "\n",
        "    # Get the current accuracy over 4 points; make this a tensor\n",
        "    y_pred = torch.cat(y_pred).view(4, 1)\n",
        "\n",
        "    accuracy = ((y_pred == y_data).sum().item())/4\n",
        "    loss = loss / 4\n",
        "\n",
        "    # Print the accuracy and the loss\n",
        "    # You want the item in the tensor thats 1x1\n",
        "    print('Loss: {} Accuracy: {}'.format(loss.item(), accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iojtw_rFAjhY"
      },
      "source": [
        "Exercise 1: Create a 2D tensor and then add a dimension of size 1 inserted at the 0th axis.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgdImVPpAm6d",
        "outputId": "ca7f4afc-8dfb-4d2e-9cae-3e85bcdb9fcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.7529,  0.1514,  2.0254],\n",
            "         [ 0.9597, -0.1363, -1.5390]]])\n"
          ]
        }
      ],
      "source": [
        "# Create a 2D tensor\n",
        "tensor_2d = torch.randn(2, 3)\n",
        "\n",
        "# Add a dimension of size 1 inserted at the 0th axis\n",
        "tensor_3d = tensor_2d.unsqueeze(0)\n",
        "print(tensor_3d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0yfuo7fAneJ"
      },
      "source": [
        "Exercise 2: Remove the extra dimension you just added to the previous tensor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goe1-DBRAnnj",
        "outputId": "ddbb0caa-7fb1-40a5-8089-6ee28c811b32"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.7529,  0.1514,  2.0254],\n",
              "        [ 0.9597, -0.1363, -1.5390]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "tensor_3d.squeeze(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAhtAtk5Any4"
      },
      "source": [
        "Exercise 3: Create a random tensor of shape 5x3 in the interval [3, 7)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCcFowEjAn8w",
        "outputId": "56037ce2-797f-47ad-e173-fe3d4e8a50f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 6.7234, -0.2551,  1.5924],\n",
              "        [ 4.5209,  3.7097,  6.0206],\n",
              "        [10.8677,  7.8818,  2.1126],\n",
              "        [ 4.9688, -4.3182, -2.3925],\n",
              "        [ 5.3777,  7.7346, -1.7977]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "torch.randn(5, 3)*4+3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvNprVRlAoEC"
      },
      "source": [
        "Exercise 4: Create a tensor with values from a normal distribution (mean=0, std=1).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Dgirc4kGAoKa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7613fc1-245c-4a24-e09e-0a3335046d3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.7708, -0.1990, -0.1236],\n",
              "        [ 0.6805,  1.2815, -0.5577],\n",
              "        [ 0.2453,  0.1268, -1.6074],\n",
              "        [-0.8201, -0.3856, -0.2435],\n",
              "        [-0.3635, -0.7848,  0.5128]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "torch.randn(5,3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1nIIGp8AoQL"
      },
      "source": [
        "exercise 5: Retrieve the indexes of all the non zero elements in the tensor torch.Tensor([1, 1, 1, 0, 1]).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCv5zbq3AoV-",
        "outputId": "d35573be-bbfe-4852-ea29-4025ceee2133"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0],\n",
            "        [1],\n",
            "        [2],\n",
            "        [4]])\n"
          ]
        }
      ],
      "source": [
        "tensor_tmp = torch.Tensor([1, 1, 1, 0, 1])\n",
        "\n",
        "# Get the indexes of non-zero elements\n",
        "non_zero_indexes = tensor_tmp.nonzero()\n",
        "print(non_zero_indexes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckErX5U1Aocz"
      },
      "source": [
        "Exercise 6: Create a random tensor of size (3,1) and then horizonally stack 4 copies together.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D3XYAnoAoig",
        "outputId": "b900250a-1f9f-4daa-d405-b8e79f500a63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4392, 0.4392, 0.4392, 0.4392],\n",
              "        [0.1415, 0.1415, 0.1415, 0.1415],\n",
              "        [0.1523, 0.1523, 0.1523, 0.1523]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "tensor_tmp1=torch.rand(3,1)\n",
        "torch.cat([tensor_tmp1]*4,dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKV3ChJrAopD"
      },
      "source": [
        "Exercise 7: Return the batch matrix-matrix product of two 3 dimensional matrices (a=torch.rand(3,4,5), b=torch.rand(3,5,4)).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ge6IErGdAovX",
        "outputId": "099874a1-7d92-4eb8-e86a-c160fb772074"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1.4059, 1.6204, 2.0652, 1.3883],\n",
              "         [1.2535, 1.1014, 1.6485, 1.1453],\n",
              "         [0.9741, 1.0626, 1.4171, 0.9004],\n",
              "         [1.1459, 0.7250, 1.2905, 0.7139]],\n",
              "\n",
              "        [[1.2585, 1.4272, 2.1518, 1.2795],\n",
              "         [1.2566, 1.6002, 1.6887, 1.1969],\n",
              "         [1.3057, 1.7112, 1.7848, 1.2747],\n",
              "         [1.2043, 1.4618, 1.7711, 1.1125]],\n",
              "\n",
              "        [[1.5032, 1.8352, 1.6611, 1.2697],\n",
              "         [1.2045, 1.4156, 1.1663, 0.9869],\n",
              "         [1.4525, 1.6554, 2.0159, 1.2713],\n",
              "         [1.3805, 1.5274, 1.7990, 1.0454]]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Create two random matrices\n",
        "a = torch.rand(3, 4, 5)\n",
        "b = torch.rand(3, 5, 4)\n",
        "\n",
        "# Calculate the batch matrix-matrix product\n",
        "torch.bmm(a, b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVI_LI_PA_2e"
      },
      "source": [
        "Exercise 8: Return the batch matrix-matrix product of a 3D matrix and a 2D matrix (a=torch.rand(3,4,5), b=torch.rand(5,4)).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpLgovtyBAA6",
        "outputId": "319694c3-d5ee-4f87-f530-16571d9052cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.7508, 0.7015, 0.5671, 1.0457],\n",
              "         [1.4711, 1.8979, 1.5328, 2.2001],\n",
              "         [1.1700, 1.3335, 0.7247, 1.6213],\n",
              "         [1.2827, 1.4309, 0.9070, 1.5566]],\n",
              "\n",
              "        [[0.9822, 1.3576, 1.0460, 1.5155],\n",
              "         [0.4780, 0.8131, 1.2121, 1.2729],\n",
              "         [0.5999, 0.8415, 1.2803, 1.7439],\n",
              "         [1.0176, 1.3580, 1.3349, 1.5591]],\n",
              "\n",
              "        [[1.2904, 1.4802, 0.7767, 1.4424],\n",
              "         [1.2067, 1.3716, 1.3407, 1.7021],\n",
              "         [0.7770, 1.0073, 0.4465, 0.9254],\n",
              "         [0.5888, 0.8920, 1.3792, 1.5051]]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Create two random matrices\n",
        "a = torch.rand(3, 4, 5)\n",
        "b = torch.rand(5, 4)\n",
        "\n",
        "# Calculate the batch matrix-matrix product\n",
        "torch.matmul(a, b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW6NxQIeBAJA"
      },
      "source": [
        "Exercise 9: Create a 1x1 random tensor and get the value inside of this tensor as a scalar. No tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_OFj9hEBAPO",
        "outputId": "df00ac0a-000b-463c-a102-17d32da2398b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7896783351898193\n"
          ]
        }
      ],
      "source": [
        "tensor_tmp2 = torch.rand(1,1)\n",
        "scalar = tensor_tmp2.item()\n",
        "print(scalar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_zAwiqrBAVd"
      },
      "source": [
        "Exercise 10: Create a 2x1 tensor and have it require a gradient. Have $x$, this tensor, hold [-2, 1]. Set $y=x_1^2 + x_2^2$ and get the gradient of y wirht respect to $x_1$ and then $x_2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z98hDPfEBAcv",
        "outputId": "9d6e9ca0-c3f6-426e-c883-8238e7319658"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gradient of y with x1: -4.0\n",
            "gradient of y with x2: 2.0\n"
          ]
        }
      ],
      "source": [
        "x=torch.tensor([[-2.0],[1.0]],requires_grad=True)\n",
        "y=x[0]**2+x[1]**2\n",
        "y.backward()\n",
        "print(\"gradient of y with x1:\",x.grad[0].item())\n",
        "print(\"gradient of y with x2:\",x.grad[1].item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGfmkpF3BAjy"
      },
      "source": [
        "Exercise 11: Check if cuda is available (it shuld be if in the Runtime setting for colab you choose the GPU). If it is, move $x$ above to a CUDA device. Create a new tensor of the same shape as $x$ and put it on the cpu. Try and add these tensors. What happens. How do you fix this?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if cuda is available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"CUDA is available!\")  if torch.cuda.is_available() else 0\n",
        "\n",
        "x = x.to(device)\n",
        "y = torch.randn(2, 1)\n",
        "y = y.cpu()\n",
        "y + x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "4WiGWsFccf5h",
        "outputId": "3c5b0e82-b709-4b69-bd23-1bfc812f0b74"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-b144d009389e>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the tensors are not both in cuda (GPU) or CPU, the error will be reported. To fix this error, I need to make sure that the two tensors are in the same device (both in GPU or CPU)."
      ],
      "metadata": {
        "id": "-F8k-Ebod_AE"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}